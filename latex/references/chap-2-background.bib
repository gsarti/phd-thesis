@book{vapnik-1995-nature,
    author={Vapnik, Vladimir N.},
    title={The Nature of Statistical Learning Theory},
    isbn={0-387-94559-8},
    publisher ={Springer-Verlag New York, Inc.},
    year={1995}
}

@book{goodfellow-etal-2016-deep,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    isbn={978-0-262-03561-3},
    publisher={MIT Press},
    url={http://www.deeplearningbook.org},
    year={2016}
}

@inbook{rumelhart-mcclelland-1987-learning,
  author={Rumelhart, David E. and McClelland, James L.},
  booktitle={Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations}, 
  title={Learning Internal Representations by Error Propagation}, 
  year={1987},
  pages={318-362},
  publisher={MIT Press},
  isbn={978-0-262-29140-8}
}

@article{hochreiter-schmidhuber-1997-long,
  author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  title = {Long short-term memory},
  journal = {Neural computation},
  number = 8,
  pages = {1735--1780},
  publisher = {MIT Press},
  volume = 9,
  year = 1997
}

@article{ba-etal-2016-layer,
      title={Layer Normalization}, 
      author={Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
      year={2016},
      url={https://arxiv.org/abs/1607.06450},
      journal={Arxiv Preprint}, 
}

@inproceedings{zhang-sennrich-2019-root,
    author = {Zhang, Biao and Sennrich, Rico},
    title = {Root Mean Square Layer Normalization},
    year = {2019},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
    articleno = {1110},
    numpages = {12}
}

@inproceedings{he-etal-2016-deep-residual,
    author = { He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian },
    booktitle = { 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) },
    title = {Deep Residual Learning for Image Recognition},
    year = {2016},
    ISSN = {1063-6919},
    pages = {770-778},
    doi = {10.1109/CVPR.2016.90},
    url = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2016.90},
    publisher = {IEEE Computer Society},
    address = {Los Alamitos, CA, USA},
    month = jun,
}

@article{hochreiter-1998-vanishing,
    author = {Hochreiter, Sepp},
    title = {The vanishing gradient problem during learning recurrent neural nets and problem solutions},
    year = {1998},
    publisher = {World Scientific Publishing Co., Inc.},
    address = {USA},
    volume = {6},
    number = {2},
    issn = {0218-4885},
    url = {https://doi.org/10.1142/S0218488598000094},
    doi = {10.1142/S0218488598000094},
    journal = {Int. J. Uncertain. Fuzziness Knowl.-Based Syst.},
    month = apr,
    pages = {107–116},
    numpages = {10},
}

@article{harris-1954-distributional,
    author = {Zellig S. Harris},
    title = {Distributional Structure},
    journal = {Word},
    volume = {10},
    number = {2-3},
    pages = {146--162},
    year = {1954},
    publisher = {Routledge},
    doi = {10.1080/00437956.1954.11659520},
}

@article{su-etal-2024-roformer,
    title = {RoFormer: Enhanced transformer with Rotary Position Embedding},
    journal = {Neurocomputing},
    volume = {568},
    pages = {127063},
    year = {2024},
    issn = {0925-2312},
    doi = {https://doi.org/10.1016/j.neucom.2023.127063},
    url = {https://www.sciencedirect.com/science/article/pii/S0925231223011864},
    author = {Jianlin Su and Murtadha Ahmed and Yu Lu and Shengfeng Pan and Wen Bo and Yunfeng Liu},
}

@inproceedings{jastrzebski-etal-2018-residual,
    title={Residual Connections Encourage Iterative Inference},
    author={Stanisław Jastrzebski and Devansh Arpit and Nicolas Ballas and Vikas Verma and Tong Che and Yoshua Bengio},
    booktitle={International Conference on Learning Representations},
    year={2018},
    url={https://openreview.net/forum?id=SJa9iHgAZ},
}

@misc{schulman-etal-2017-proximal,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1707.06347}, 
}

@inproceedings{zeiler-etal-2011-adaptive,
  author={Zeiler, Matthew D. and Taylor, Graham W. and Fergus, Rob},
  booktitle={2011 International Conference on Computer Vision (ICCV)}, 
  title={Adaptive deconvolutional networks for mid and high level feature learning}, 
  year={2011},
  pages={2018-2025},
  doi={10.1109/ICCV.2011.6126474}
}

@phdthesis{fel-2024-sparks,
  title={Sparks of Explainability: Recent Advancements in Explaining Large Vision Models},
  author={Thomas Fel},
  year={2024},
  school={University of Toulouse},
  url={https://arxiv.org/abs/2502.01048}
}

@misc{smilkov-etal-2017-smoothgrad,
      title={SmoothGrad: removing noise by adding noise}, 
      author={Daniel Smilkov and Nikhil Thorat and Been Kim and Fernanda Viégas and Martin Wattenberg},
      year={2017},
      eprint={1706.03825},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{bach-etal-2015-pixel,
    doi = {10.1371/journal.pone.0130140},
    author = {Bach, Sebastian AND Binder, Alexander AND Montavon, Grégoire AND Klauschen, Frederick AND Müller, Klaus-Robert AND Samek, Wojciech},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation},
    year = {2015},
    month = {07},
    volume = {10},
    url = {https://doi.org/10.1371/journal.pone.0130140},
    pages = {1-46},
    number = {7},
}

@inproceedings{achtibat-etal-2024-attnlrp,
    author = {Achtibat, Reduan and Hatefi, Sayed Mohammad Vakilzadeh and Dreyer, Maximilian and Jain, Aakriti and Wiegand, Thomas and Lapuschkin, Sebastian and Samek, Wojciech},
    title = {AttnLRP: attention-aware layer-wise relevance propagation for transformers},
    year = {2024},
    publisher = {JMLR.org},
    booktitle = {Proceedings of the 41st International Conference on Machine Learning},
    articleno = {6},
    numpages = {34},
    location = {Vienna, Austria},
    series = {ICML'24}
}

@article{covert-etal-2021-explaining,
  author  = {Ian Covert and Scott Lundberg and Su-In Lee},
  title   = {Explaining by Removing: A Unified Framework for Model Explanation},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {209},
  pages   = {1--90},
  url     = {http://jmlr.org/papers/v22/20-1316.html}
}

@inproceedings{sixt-etal-2020-explanations,
  title = {When Explanations Lie: Why Many Modified {BP} Attributions Fail},
  author = {Sixt, Leon and Granz, Maximilian and Landgraf, Tim},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  pages = {9046--9057},
  year = {2020},
  editor = {III, Hal Daumé and Singh, Aarti},
  volume = {119},
  series = {Proceedings of Machine Learning Research},
  month = {13--18 Jul},
  publisher = {PMLR},
  url = {https://proceedings.mlr.press/v119/sixt20a.html},
}

@inproceedings{crabbe-vanderschaar-2023-evaluating,
    title={Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance},
    author={Jonathan Crabb{\'e} and Mihaela van der Schaar},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=5UwnKSgY6u}
}

@article{krishna-etal-2024-disagreement,
    title={The Disagreement Problem in Explainable Machine Learning: A Practitioner{\textquoteright}s Perspective},
    author={Satyapriya Krishna and Tessa Han and Alex Gu and Steven Wu and Shahin Jabbari and Himabindu Lakkaraju},
    journal={Transactions on Machine Learning Research},
    issn={2835-8856},
    year={2024},
    url={https://openreview.net/forum?id=jESY2WTZCe},
}

@inproceedings{adebayo-etal-2020-debugging,
    author = {Adebayo, Julius and Muelly, Michael and Liccardi, Ilaria and Kim, Been},
    title = {Debugging tests for model explanations},
    year = {2020},
    isbn = {9781713829546},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
    articleno = {60},
    numpages = {13},
    location = {Vancouver, BC, Canada},
    series = {NIPS'20}
}

@inproceedings{adebayo-etal-2022-posthoc,
    title={Post hoc Explanations may be Ineffective for Detecting Unknown Spurious Correlation},
    author={Julius Adebayo and Michael Muelly and Harold Abelson and Been Kim},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=xNOVfCCvDpM}
}

@article{bilodeau-etal-2024-impossibility,
    author = {Blair Bilodeau  and Natasha Jaques  and Pang Wei Koh  and Been Kim },
    title = {Impossibility theorems for feature attribution},
    journal = {Proceedings of the National Academy of Sciences},
    volume = {121},
    number = {2},
    pages = {e2304406120},
    year = {2024},
    doi = {10.1073/pnas.2304406120},
    URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2304406120},
}

@article{tenney-etal-2024-interactive,
    title={Interactive Prompt Debugging with Sequence Salience}, 
    author={Ian Tenney and Ryan Mullins and Bin Du and Shree Pandya and Minsuk Kahng and Lucas Dixon},
    year={2024},
    journal={Arxiv},
    url={https://arxiv.org/abs/2404.07498},
}

@inproceedings{park-etal-2023-linear,
    title={The Linear Representation Hypothesis and the Geometry of Large Language Models},
    author={Kiho Park and Yo Joong Choe and Victor Veitch},
    booktitle={Causal Representation Learning Workshop at NeurIPS 2023},
    year={2023},
    url={https://openreview.net/forum?id=T0PoOJg8cK}
}

@inproceedings{arditi-etal-2025-refusal,
    author = {Arditi, Andy and Obeso, Oscar and Syed, Aaquib and Paleka, Daniel and Panickssery, Nina and Gurnee, Wes and Nanda, Neel},
    title = {Refusal in language models is mediated by a single direction},
    year = {2025},
    isbn = {9798331314385},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    abstract = {Conversational large language models are fine-tuned for both instruction-following and safety, resulting in models that obey benign requests but refuse harmful ones. While this refusal behavior is widespread across chat models, its underlying mechanisms remain poorly understood. In this work, we show that refusal is mediated by a one-dimensional subspace, across 13 popular open-source chat models up to 72B parameters in size. Specifically, for each model, we find a single direction such that erasing this direction from the model's residual stream activations prevents it from refusing harmful instructions, while adding this direction elicits refusal on even harmless instructions. Leveraging this insight, we propose a novel white-box jailbreak method that surgically disables refusal with minimal effect on other capabilities. Finally, we mechanistically analyze how adversarial suffixes suppress propagation of the refusal-mediating direction. Our findings underscore the brittleness of current safety fine-tuning methods. More broadly, our work showcases how an understanding of model internals can be leveraged to develop practical methods for controlling model behavior. Code available at https://github.com/andyrdt/refusal_direction.},
    booktitle = {Proceedings of the 38th International Conference on Neural Information Processing Systems},
    articleno = {4322},
    numpages = {47},
    location = {Vancouver, BC, Canada},
    series = {NIPS '24}
}

@inproceedings{marks-tegmark-2024-geometry,
    title={The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets}, 
    author={Samuel Marks and Max Tegmark},
    year={2024},
    booktitle={Proceedings of the 1st Conference on Language Modeling (COLM)},
    url={https://arxiv.org/abs/2310.06824}, 
}

@misc{smolensky-1986-neural,
    author = {Smolensky, P.},
    title = {Neural and conceptual interpretation of PDP models},
    year = {1986},
    isbn = {0262631105},
    publisher = {MIT Press},
    address = {Cambridge, MA, USA},
    booktitle = {Parallel Distributed Processing: Explorations in the Microstructure, Vol. 2: Psychological and Biological Models},
    pages = {390–431},
    numpages = {42},
}

@article{olah-2023-distributed,
   title={Distributed Representations: Composition \& Superposition},
   author={Olah, Chris},
   year={2023},
   journal={Transformer Circuits Thread},
   url={https://transformer-circuits.pub/2023/superposition-composition/index.html}
}

@article{elhage-etal-2022-toy,
    title={Toy Models of Superposition},
    author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and Grosse, Roger and McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Wattenberg, Martin and Olah, Christopher},
    year={2022},
    journal={Transformer Circuits Thread},
    url={https://transformer-circuits.pub/2022/toy_model/index.html}
}

@article{olshausen-field-1997-sparse,
    author = {Bruno A. Olshausen and David J. Field},
    title = {Sparse coding with an overcomplete basis set: A strategy employed by V1?},
    journal = {Vision Research},
    volume = {37},
    number = {23},
    pages = {3311-3325},
    year = {1997},
    issn = {0042-6989},
    doi = {https://doi.org/10.1016/S0042-6989(97)00169-7},
    url = {https://www.sciencedirect.com/science/article/pii/S0042698997001697},
}

@article{donoho-elad-2003-optimally,
    author = {David L. Donoho  and Michael Elad },
    title = {Optimally sparse representation in general (nonorthogonal) dictionaries via \&\#x2113;<sup>1</sup> minimization},
    journal = {Proceedings of the National Academy of Sciences},
    volume = {100},
    number = {5},
    pages = {2197-2202},
    year = {2003},
    doi = {10.1073/pnas.0437847100},
    URL = {https://www.pnas.org/doi/abs/10.1073/pnas.0437847100},
}

@article{bricken-etal-2023-monosemanticity,
    title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
    author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
    year={2023},
    journal={Transformer Circuits Thread},
    url={https://transformer-circuits.pub/2023/monosemantic-features/index.html}
}

@article{hutchins-2001-machine,
    author = {Hutchins, W.},
    year = {2001},
    month = {01},
    pages = {7-31},
    title = {Machine Translation over fifty years},
    volume = {23},
    journal = {Histoire Épistémologie Langage},
    doi = {10.3406/hel.2001.2815}
}

@inproceedings{alves-etal-2024-tower,
    title={Tower: An Open Multilingual Large Language Model for Translation-Related Tasks},
    author={Duarte Miguel Alves and Jos{\'e} Pombal and Nuno M Guerreiro and Pedro Henrique Martins and Jo{\~a}o Alves and Amin Farajian and Ben Peters and Ricardo Rei and Patrick Fernandes and Sweta Agrawal and Pierre Colombo and Jos{\'e} G. C. de Souza and Andre Martins},
    booktitle={First Conference on Language Modeling},
    year={2024},
    url={https://openreview.net/forum?id=EHPns3hVkj}
}

@inproceedings{xu-etal-2024-paradigm,
    title={A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models},
    author={Haoran Xu and Young Jin Kim and Amr Sharaf and Hany Hassan Awadalla},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=farT6XXntP}
}

@book{bowker-2002-computer,
    url = {http://www.jstor.org/stable/j.ctt1ch78kf},
    author = {Lynne Bowker},
    publisher = {University of Ottawa Press},
    title = {Computer-Aided Translation Technology: A Practical Introduction},
    year = {2002},
    isbn = {9780776615677}
}

@article{church-hovy-1993-good,
 author    = {Church, Kenneth W. and Hovy, Eduard H.},
 title     = {Good applications for crummy machine translation},
 journal   = {Machine Translation},
 volume    = {8},
 number    = {4},
 pages     = {239--258},
 year      = {1993},
 doi       = {10.1007/BF00981759},
 abstract  = {Ideally, we might hope to improve the performance of our MT systems by improving the system, but it might be even more important to improve performance by looking for a more appropriate application. A survey of the literature on evaluation of MT systems seems to suggest that the success of the evaluation often depends very strongly on the selection of an appropriate application. If the application is well-chosen, then it often becomes fairly clear how the system should be evaluated. Moreover, the evaluation is likely to make the system look good. Conversely, if the application is not clearly identified (or worse, if the application is poorly chosen), then it is often very difficult to find a satisfying evaluation paradigm. We begin our discussion with a brief review of some evaluation metrics that have been tried in the past and conclude that it is difficult to identify a satisfying evaluation paradigm that will make sense over all possible applications. It is probably wise to identify the application first, and then we will be in a much better position to address evaluation questions. The discussion will then turn to the main point, an essay on how to pick a good niche application for state-of-the-art (crummy) machine translation.}
}

@article{cadwell-etal-2016-human,
   author = "Cadwell, Patrick and Castilho, Sheila and O'Brien, Sharon and Mitchell, Linda",
   title = "Human factors in machine translation and post-editing among institutional translators", 
   journal= "Translation Spaces",
   year = "2016",
   volume = "5",
   number = "2",
   pages = "222-243",
   doi = "https://doi.org/10.1075/ts.5.2.04cad",
   url = "https://www.jbe-platform.com/content/journals/10.1075/ts.5.2.04cad",
   publisher = "John Benjamins",
   issn = "2211-3711",
}

@article{daems-etal-2017-identifying,
    author={Daems, Joke  and Vandepitte, Sonia  and Hartsuiker, Robert J.  and Macken, Lieve },
    title={Identifying the Machine Translation Error Types with the Greatest Impact on Post-editing Effort},
    journal={Frontiers in Psychology},
    volume={8},
    year={2017},
    url={https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2017.01282},
    doi={10.3389/fpsyg.2017.01282},
    issn={1664-1078},
}

@article{garcia-2009-beyond,
    author = {Garcia, Ignacio},
    year = {2009},
    month = {07},
    title = {Beyond Translation Memory: Computers and the Professional Translator},
    journal = {The Journal of Specialised Translation},
    doi = {10.26034/cm.jostrans.2009.624}
}

@inproceedings{zhang-etal-2020-bertscore,
    title={BERTScore: Evaluating Text Generation with BERT},
    author={Tianyi Zhang$^*$ and Varsha Kishore$^*$ and Felix Wu$^*$ and Kilian Q. Weinberger and Yoav Artzi},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=SkeHuCVFDr}
}

@inproceedings{tamchyna-etal-2021-deploying,
    title = "Deploying {MT} Quality Estimation on a large scale: Lessons learned and open questions",
    author = "Tamchyna, Ale{\v{s}}",
    editor = "Campbell, Janice  and
      Huyck, Ben  and
      Larocca, Stephen  and
      Marciano, Jay  and
      Savenkov, Konstantin  and
      Yanishevsky, Alex",
    booktitle = "Proceedings of Machine Translation Summit XVIII: Users and Providers Track",
    month = aug,
    year = "2021",
    address = "Virtual",
    publisher = "Association for Machine Translation in the Americas",
    url = "https://aclanthology.org/2021.mtsummit-up.21/",
    pages = "291--305",
}

@inproceedings{conneau-lample-2019-cross,
    author = {Conneau, Alexis and Lample, Guillaume},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    publisher = {Curran Associates, Inc.},
    title = {Cross-lingual Language Model Pretraining},
    url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/c04c19c2c2474dbf5f7ac4372c5b9af1-Paper.pdf},
    volume = {32},
    year = {2019}
}

@article{lee-etal-2023-survey,
    AUTHOR = {Lee, Seungjun and Lee, Jungseob and Moon, Hyeonseok and Park, Chanjun and Seo, Jaehyung and Eo, Sugyeong and Koo, Seonmin and Lim, Heuiseok},
    TITLE = {A Survey on Evaluation Metrics for Machine Translation},
    JOURNAL = {Mathematics},
    VOLUME = {11},
    YEAR = {2023},
    NUMBER = {4},
    ARTICLE-NUMBER = {1006},
    URL = {https://www.mdpi.com/2227-7390/11/4/1006},
    ISSN = {2227-7390},
    ABSTRACT = {The success of Transformer architecture has seen increased interest in machine translation (MT). The translation quality of neural network-based MT transcends that of translations derived using statistical methods. This growth in MT research has entailed the development of accurate automatic evaluation metrics that allow us to track the performance of MT. However, automatically evaluating and comparing MT systems is a challenging task. Several studies have shown that traditional metrics (e.g., BLEU, TER) show poor performance in capturing semantic similarity between MT outputs and human reference translations. To date, to improve performance, various evaluation metrics have been proposed using the Transformer architecture. However, a systematic and comprehensive literature review on these metrics is still missing. Therefore, it is necessary to survey the existing automatic evaluation metrics of MT to enable both established and new researchers to quickly understand the trend of MT evaluation over the past few years. In this survey, we present the trend of automatic evaluation metrics. To better understand the developments in the field, we provide the taxonomy of the automatic evaluation metrics. Then, we explain the key contributions and shortcomings of the metrics. In addition, we select the representative metrics from the taxonomy, and conduct experiments to analyze related problems. Finally, we discuss the limitation of the current automatic metric studies through the experimentation and our suggestions for further research to improve the automatic evaluation metrics.},
    DOI = {10.3390/math11041006}
}

@article{turchi-etal-2017-continuous,
 journal = {The Prague Bulletin of Mathematical Linguistics},
 title = {Continuous Learning from Human Post-Edits for Neural Machine Translation},
 author = {Marco Turchi and Matteo Negri and M. Amin Farajian and Marcello Federico},
 year = {2017},
 month = {June},
 volume = {108},
 pages = {233--244},
 doi = {10.1515/pralin-2017-0023},
 issn = {0032-6585},
 url = {https://ufal.mff.cuni.cz/pbml/108/art-turchi-negri-farajian-federico.pdf}
}

@article{karimova-etal-2018-user,
  author    = {Karimova, Sariya and Simianer, Patrick and Riezler, Stefan},
  title     = {A user-study on online adaptation of neural machine translation to human post-edits},
  journal   = {Machine Translation},
  year      = {2018},
  volume    = {32},
  number    = {4},
  pages     = {309--324},
  month     = {12},
  issn      = {1573-0573},
  doi       = {10.1007/s10590-018-9224-8},
  url       = {https://doi.org/10.1007/s10590-018-9224-8}
}

@book{specia-etal-2018-quality,
    author = {Specia, Lucia and Scarton, Carolina and Paetzold, Gustavo Henrique and Hirst, Graeme},
    title = {Quality Estimation for Machine Translation},
    year = {2018},
    isbn = {1681733730},
    publisher = {Morgan \& Claypool Publishers},
}


