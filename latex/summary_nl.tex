Neurale taalmodellen hebben voor een revolutie gezorgd in het vakgebied van de natuurlijke taalverwerking en zijn snel uitgegroeid tot essentiële instrumenten voor een breed scala aan praktische toepassingen. Recente vorderingen in het onderzoek naar \textit{interpreteerbaarheid} boden waardevolle inzichten in de interne werking van deze systemen, maar slaagden er vaak niet in zich te vertalen naar verbeteringen voor gebruikers in reële scenario's. Dit proefschrift onderzoekt de ontwikkeling van methoden, gebaseerd op interpreteerbaarheidsonderzoek, om de betrouwbaarheid en bestuurbaarheid van neurale machinevertaalsystemen te verbeteren, op een \textit{end-to-end}-manier: van concept tot en met experimenten met eindgebruikers. De bevindingen gaan in op fundamentele vragen over hoe taalmodellen contextuele informatie benutten, hoe hun generatieprocessen kunnen worden gestuurd voor personalisatie, en hoe inzichten uit interpreteerbaarheidsonderzoek de professionele vertaalpraktijk kunnen verbeteren.

Het proefschrift is opgebouwd in drie onderling verbonden delen. \textbf{Deel I} ontwikkelt fundamentele instrumenten en methoden om te begrijpen hoe taalmodellen contextuele informatie gebruiken tijdens het genereren van tekst. 
Om te beginnen introduceren we Inseq, een open-source toolkit voor interactieve analyse van taalmodelgedrag, en laten we zien hoe het gebruikt kan worden voor het detecteren van genderbias in machinevertaling en voor activatie-attributie met gradiënt-gebaseerde methoden. Vervolgens ontwerpen we \textsc{PECoRe}, een raamwerk dat \textit{contrastieve inputattributie} gebruikt om te kwantificeren hoe taalmodellen contextuele informatie benutten, en we tonen de effectiviteit hiervan aan bij het detecteren van contextinvloed in contextbewuste machinevertaalsystemen.
Tot slot breiden we \textsc{PECoRe} uit naar 'retrieval-augmented generation' (RAG), waarbij we de interne werking van het model gebruiken om betrouwbare, efficiënte en hoogwaardige citaten te produceren voor het beantwoorden van openboekvragen.

\textbf{Deel II} verschuift de focus van ons onderzoek van analyse naar interventie, en verkent methoden om de vertaaloutput te beheersen met technieken gebaseerd op \textit{prompting} en \textit{sturing}. We presenteren eerst \textsc{Ramp}, een 'retrieval-augmented prompting'-techniek die relevante voorbeelden en stijl-labels benut voor attribuut-gestuurde vertaling. Vervolgens verplaatsen we ons naar het meer uitdagende domein van de literaire vertaling, waarbij we de effectiviteit benadrukken van sturingsinterventies bij het conditioneren van de modelgeneratie door hun interne representaties chirurgisch aan te passen. In het bijzonder tonen we aan dat interpreteerbare concepten, geëxtraheerd door getrainde sparse autoencoders, kunnen worden gebruikt om persoonlijke vertaalstijlen van menselijke professionele vertalers na te bootsen, en dat succesvolle prompting- en sturing-benaderingen convergeren naar vergelijkbare mechanistische oplossingen.

Ten slotte onderzoekt \textbf{Deel III} hoe inzichten uit de interne werking van modellen menselijke post-editors kunnen informeren binnen professionele vertaalworkflows. We beginnen met het uitvoeren van een gebruikersstudie over post-editing in zes typologisch diverse talen omvat (\textsc{DivEMT}). Deze studie toont aan dat de productiviteitswinst bij vertalen dramatisch varieert tussen taalparen, waarbij typologische afstand invloedrijker is dan traditionele kwaliteitsmetrieken.
Onze tweede studie, QE4PE, onderzoekt hoe foutmarkeringen op woordniveau de productiviteit van professionele post-editors en de kwaliteit van hun vertalingen beïnvloeden, waarbij zowel gesuperviseerde als op interpreteerbaarheid gebaseerde benaderingen worden meegenomen. We sluiten af met een brede evaluatie van niet-gesuperviseerde methoden voor kwaliteitsbeoordeling, waaruit blijkt dat foutdetectiebenaderingen gebaseerd op interpreteerbaarheid beter kunnen presteren dan gesuperviseerde baselines. We benadrukken tevens het belang van kalibratie en meervoudige annotaties om rekening te houden met menselijke variatie in labeling.

In het geheel genomen levert dit proefschrift een bijdrage aan het vakgebied van de interpreteerbaarheid van machinevertaling door toegankelijke tools en methoden te ontwikkelen voor het begrijpen van contextgebruik, het mogelijk maken van fijnmazige beheersing van de vertaaloutput, en het leveren van empirisch bewijs voor het gebruik van interpreteerbaarheid in professionele vertaalworkflows. Deze bijdragen leggen samen het fundament voor de volgende generatie van betrouwbare, beheersbare en gebruikersgerichte vertaalsystemen.