Hoewel neurale taalmodellen opmerkelijk effectief zijn, blijven hun interne mechanismen grotendeels ondoorzichtig. Dit proefschrift onderzoekt de interne werking van neurale machinevertalingssystemen (MT) door de lens van interpreteerbaarheid, en ontwikkelt nieuwe methoden om deze systemen te begrijpen, te besturen en te integreren in menselijke vertaalworkflows. Het onderzoek behandelt fundamentele vragen over hoe taalmodellen contextuele informatie benutten, hoe hun generatieprocessen kunnen worden gestuurd voor personalisatie, en hoe inzichten uit interpreteerbaarheid de professionele vertaalpraktijk kunnen verbeteren.

Het eerste deel van het proefschrift legt een kader vast voor het analyseren van contextgebruik in taalmodellen. We introduceren Inseq, een open-source toolkit voor interactieve analyse van het gedrag van taalmodellen, en ontwikkelen 	extsc{PECoRe}, een raamwerk dat contrastieve inputattributie gebruikt om te kwantificeren hoe taalmodellen contextuele informatie benutten. We breiden dit uit naar het genereren van antwoorden met behulp van opgehaalde informatie, en tonen aan dat de interne werking van het model betrouwbare citaten van hoge kwaliteit kan produceren voor open-boek vraagbeantwoording.

Het tweede deel verschuift van analyse naar interventie, en onderzoekt twee paradigma's voor het conditioneren van MT-outputs. We presenteren eerst 	extsc{Ramp}, een techniek die het prompten verbetert door relevante voorbeelden op te halen voor attribuut-gestuurde vertaling. Vervolgens gebruiken we sparse auto-encoders om vertalingen te sturen naar de stijl van individuele vertalers in het uitdagende domein van de literaire vertaling. Onze analyse onthult dat succesvolle prompting- en sturingsbenaderingen convergeren naar vergelijkbare mechanistische oplossingen.

Het laatste deel onderzoekt hoe inzichten uit de interne werking van modellen menselijke redacteuren kunnen informeren in de dagelijkse vertaalpraktijk. We presenteren 	extsc{DivEMT}, de eerste cross-linguale post-editing dataset die zes typologisch diverse talen omvat, waaruit blijkt dat traditionele MT-kwaliteitsmetrieken niet correleren met de productiviteit van post-editing. Onze tweede studie, QE4PE, onderzoekt hoe het markeren van fouten op woordniveau de productiviteit van vertalers en de kwaliteit van de output be√Ønvloedt. Onze evaluatie van ongesuperviseerde methoden voor kwaliteitsschatting toont aan dat benaderingen gebaseerd op de interne werking van het model beter kunnen presteren dan gesuperviseerde baselines, wat het belang benadrukt van kalibratie en meerdere annotaties om rekening te houden met menselijke labelvariatie.

Samenvattend bevordert dit proefschrift het veld van de interpreteerbaarheid van machinevertaling door toegankelijke tools te ontwikkelen voor het begrijpen van contextgebruik, het mogelijk maken van fijnmazige controle over vertaalresultaten en het vaststellen van empirisch bewijs voor het gebruik van de interne werking van het model in professionele vertaalworkflows. Deze bijdragen leggen de basis voor transparantere, controleerbare en mensgerichte vertaalsystemen.