Hoewel op neurale netwerken gebaseerde taalmodellen opmerkelijk effectief zijn gebleken voor natuurlijke taalverwerkingstaken, blijven hun interne mechanismen grotendeels ondoorzichtig voor zowel onderzoekers als beoefenaars. Recente ontwikkelingen in interpretatieonderzoek hebben licht geworpen op hoe deze systemen werken, met name bij het identificeren van model-subnetwerken die verantwoordelijk zijn voor specifieke taken en het begrijpen van hoe kennis wordt opgeslagen en gebruikt door modellen. Interpretatieonderzoek heeft echter kritiek gekregen omdat het zelden bruikbare resultaten oplevert die het ontwerp of het gebruik van taalmodellen in de praktijk op een zinvolle manier zouden verbeteren. Dit proefschrift onderzoekt de innerlijke werking van neurale machinevertalingssystemen (MT-systemen) door de lens van interpreteerbaarheid en ontwikkelt nieuwe methoden om deze systemen te begrijpen, te controleren en te integreren in menselijke vertaalworkflows. Het onderzoek behandelt fundamentele vragen over hoe taalmodellen contextuele informatie benutten, hoe hun generatieprocessen kunnen worden aangestuurd voor personalisatie en hoe inzichten in interpretabiliteit professionele vertaalpraktijken kunnen verbeteren.

Het eerste deel biedt een uitgebreide infrastructuur en methodologisch kader voor het analyseren van contextgebruik in taalmodellen en machinevertalingssystemen. We beginnen met de introductie van Inseq, een open-source toolkit die is ontworpen om de toegang tot interactieve analyses van het gedrag van taalmodellen te democratiseren en een eenvoudige uniforme interface te bieden voor ultramoderne interpretatiemethoden voor inputtoewijzing. Voortbouwend op deze basis ontwikkelen we \textsc{PECoRe}, een end-to-end framework dat contrastieve inputtoewijzing gebruikt om nauwkeurig te kwantificeren hoe taalmodellen contextuele informatie benutten tijdens het genereren, en passen we het toe om contextinvloed te bestuderen in contextbewuste machinevertaling. We breiden ons onderzoek verder uit naar generatie met ophaalverbetering met grote taalmodellen, waaruit blijkt dat modelinterna getrouwe citaten van hoge kwaliteit kunnen produceren voor contextparagrafen voor het beantwoorden van open-boekvragen in meerdere talen.

Het tweede deel verschuift de focus van analyse naar interventie en verkent twee complementaire paradigma's voor het conditioneren van de output van machinevertalingen om te voldoen aan gebruikersspecifieke vereisten. We presenteren eerst \textsc{Ramp}, een ophaal-augmented prompting-techniek die semantische gelijkenis en expliciete attribuutmarkering gebruikt om attribuutgestuurde vertaling te bereiken. Vervolgens gaan we verder met meer geavanceerde personalisatie door directe interventie op modelrepresentaties, waarbij we schaarse auto-encoders gebruiken om vertalingen te sturen naar individuele vertaalstijlen in het uitdagende domein van literaire vertaling. Onze vergelijkende analyse laat zien dat succesvolle prompting- en op interpretatie gebaseerde sturingsbenaderingen samenkomen in vergelijkbare mechanistische oplossingen, waarbij fundamentele principes van generatieconditionering in neurale taalmodellen worden blootgelegd.

Het laatste deel onderzoekt hoe inzichten die zijn afgeleid van de interne werking van het model menselijke redacteuren kunnen informeren in vertaalworkflows in de echte wereld, door middel van uitgebreide meertalige gebruikersstudies waarbij professionele vertalers betrokken zijn. We presenteren eerst \textsc{DivEMT}, de eerste publiekelijk beschikbare meertalige post-editing dataset die zes typologisch verschillende talen omvat, waaruit blijkt dat traditionele MT-kwaliteitsstatistieken niet correleren met de werkelijke post-editing productiviteit en dat taalverwantschap de efficiëntie van het bewerken aanzienlijk beïnvloedt. Voortbouwend op deze inzichten onderzoekt onze tweede studie QE4PE hoe fouten op woordniveau - inclusief fouten die worden gegenereerd door ongesuperviseerde onzekerheidsgebaseerde methoden - de productiviteit van vertalers en de uitvoerkwaliteit in realistische bewerkingsscenario's beïnvloeden. Onze evaluatie van ongesuperviseerde kwaliteitsschattingsmethoden toont aan dat benaderingen op basis van modelinterna beter kunnen presteren dan gesuperviseerde baselines in downstream bruikbaarheid, wat het belang benadrukt van methodiekalibratie en meerdere kwaliteitsannotaties om rekening te houden met menselijke labelvariatie.

Over het algemeen bevordert dit proefschrift het veld van de interpretatie van machinevertaling in drie dimensies: het ontwikkelt toegankelijke tools en kaders voor het begrijpen van contextgebruik in generatieve modellen, het demonstreert hoe interpretatiemethoden een fijnmazige controle over vertaalresultaten mogelijk kunnen maken en het levert empirisch bewijs voor het gebruik van interne professionele vertaalworkflows van taalmodellen. Deze bijdragen leggen de basis voor meer transparante, controleerbare en mensgerichte vertaalsystemen, met het potentieel om de productiviteit en effectiviteit van menselijke vertalers in hun interacties met AI-systemen te verbeteren.