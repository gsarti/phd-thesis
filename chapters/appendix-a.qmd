# Context Usage in Machine Translation and Multilingual NLP {#sec-appendix-a}

## Attributing Language Model Generations with the Inseq Toolkit {#sec-inseq-appendix}

### Additional Details on Turkish Gender Bias Case Study {#sec-inseq-appendix-turkish-gender-bias}

[@tbl-turkish-wordlist] shows the list of occupation terms used in the gender bias case study ([@sec-chap3-gender-bias]).
We correlate the ranking of occupations based on the selected attribution metrics and probabilities with U.S. labor statistics^[[`https://github.com/rudinger/winogender-schemas`](https://github.com/rudinger/winogender-schemas/blob/master/data/occupations-stats.tsv) (`bls_pct_female` column)]. Table [@tbl-m2m-gender-example] example was taken from the BUG dataset [@levy-etal-2021-collecting-large].

| **Turkish** | **English** | **Turkish** | **English** |
|---------|---------|---------|---------|
| teknisyen | technician | memur | officer |
| muhasebeci | accountant | patolog | pathologist |
| süpervizör | supervisor | öğretmen | teacher |
| mühendis | engineer | avukat | lawyer |
| işçi | worker | planlamacı | planner |
| eğitimci | educator | yönetici | practitioner |
| katip | clerk | tesisatçı | plumber |
| danışman | consultant | eğitmen | instructor |
| müfettiş | inspector | cerrah | surgeon |
| tamirci | mechanic | veteriner | veterinarian |
| müdür | manager | kimyager | chemist |
| terapist | therapist | makinist | machinist |
| resepsiyonist | receptionist | mimar | architect |
| kütüphaneci | librarian | kuaför | hairdresser |
| ressam | painter | fırıncı | baker |
| eczacı | pharmacist | programlamacı | programmer |
| kapıcı | janitor | itfaiyeci | firefighter |
| psikolog | psychologist | bilim insanı | scientist |
| doktor | physician | sevk memuru | dispatcher |
| marangoz | carpenter | kasiyer | cashier |
| hemşire | nurse | komisyoncu | broker |
| araştırmacı | investigator | şef | chef |
| barmen | bartender | doktor | doctor |
| uzman | specialist | sekreter | secretary |
| elektrikçi | electrician | | |

: List of the 49 Turkish occupation terms and their English translations used in the gender bias case study. {#tbl-turkish-wordlist}

### Example of Pair Aggregation for Contrastive MT Comparison {#sec-inseq-appendix-pair-agg-gender-swap}

An example of gender translation pair using the synthetic template of [@sec-chap3-gender-bias] is show in [@fig-ex-gender-pair-agg], highlighting a large drop in probability when switching the gendered pronoun for highly gender-stereotypical professions, similar to [@tbl-turkish-gender-bias] results.

::: {#fig-ex-gender-pair-agg}
```python
import inseq
from inseq.data.aggregator import *

# Load the TR-EN translation model and attach the IG method
model = inseq.load_model(
    "Helsinki-NLP/opus-mt-tr-en", "integrated_gradients"
)

# Forced decoding. Return probabilities, no target attr.
out = model.attribute(
    ["O bir teknisyen", "O bir teknisyen"],
    ["She is a technician.","He is a technician."],
    step_scores=["probability"],
)

# Aggregation pipeline composed by two steps:
# 1. Aggregate subword tokens across all dimensions:
# 2. Aggregate hidden size to produce token-level attributions
subw_aggregator = AggregatorPipeline(
    [SubwordAggregator, SequenceAttributionAggregator]
)
masculine = out[0].aggregate(aggregator=subw_aggregator)
feminine = out[1].aggregate(aggregator=subw_aggregator)

# Take the diff of the scores of the two attributions
masculine.show(aggregator=PairAggregator, paired_attr=feminine)
```

![](../figures/chap-3-inseq/tr_en_pair_aggr_example.png){width=60% fig-align="center"}

Comparing attributions for a synthetic Turkish-to-English translation example with underspecified source pronoun gender using a MarianMT Turkish-to-English translation model [@tiedemann-2020-tatoeba]. Values in the visualized attribution matrix show a 46% higher probability of producing the masculine pronoun in the translation and a relative decrease of 18.4% in the importance of the Turkish occupation term compared to the feminine pronoun case.
:::

### Example of Quantized Contrastive Attribution of Factual Knowledge {#sec-inseq-appendix-factual-knowledge}

[@fig-ex-cat-counterfact-code] presents code used in [@sec-chap3-rome-repro] case study, with visualized attribution scores for contrastive examples presented in [@fig-ex-cat-counterfact-plots].

:::{#fig-ex-cat-counterfact-code}
```python
import inseq
from datasets import load_dataset
from transformers import AutoModelForCausalLM, AutoTokenizer

# The model is loaded in 8-bit on available GPUs
model = AutoModelForCausalLM.from_pretrained(
    "gpt2-xl", load_in_8bit=True, device_map="auto"
)
# Counterfact datasets used by Meng et al. (2022)
data = load_dataset("NeelNanda/counterfact-tracing")["train"]

# GPT-2 XL is a Transformer model with 48 layers
for layer in range(48):
    attrib_model = inseq.load_model(
        model,
        "layer_gradient_x_activation",
        tokenizer="gpt2-xl",
        target_layer=model.transformer.h[layer].mlp,
    )
    for i, ex in data:
        # e.g. "The capital of Second Spanish Republic is"
        # -> Madrid (true) / Paris (false)
        prompt = ex["relation"].format(ex["subject"])
        true_answer = prompt + ex["target_true"]
        false_answer = prompt + ex["target_false"] 
        # Contrastive attribution of true vs false answer
        out = attrib_model.attribute(
            prompt,
            true_answer,
            attributed_fn="contrast_prob_diff",
            contrast_targets=false_answer,
            show_progress=False,
        )
```

Example code to contrastively attribute factual statements from the Counterfact Tracing dataset, using Layer Gradient $\times$ Activation to compute importance scores until intermediate layers of the GPT2-XL model.
:::

::: {#fig-ex-cat-counterfact-plots layout-ncol="2"}

![](../figures/chap-3-inseq/cat_example_1.png){width=50% fig-align="center"}

![](../figures/chap-3-inseq/cat_example_2.png){width=50% fig-align="center"}

![](../figures/chap-3-inseq/cat_example_3.png){width=50% fig-align="center"}

![](../figures/chap-3-inseq/cat_example_4.png){width=50% fig-align="center"}

![](../figures/chap-3-inseq/cat_example_5.png){width=50% fig-align="center"}

![](../figures/chap-3-inseq/cat_example_6.png){width=50% fig-align="center"}

Visualization of contrastive attribution scores on a subset of layers (23 to 48) for some selected dataset examples. Plot labels show the contrastive pairs of false $\rightarrow$ true answer used as attribution targets.
:::

{{< pagebreak >}}

## Quantifying Context Usage in Neural Machine Translation {#sec-pecore-appendix}

```pseudocode
#| label: alg-pecore
#| pdf-placement: "ht!"

\begin{algorithm}
\caption{PECoRe cue-target extraction process}
\begin{algorithmic}
\Require $C, x$ (Input context and current sequences), $\theta$ (Model parameters), $s_{\text{cti}}, s_{\text{cci}}$ (Selector functions), $\mathcal{M}$ (Contrastive metrics), $f_\text{att}$ (Contrastive attribution method), $f_\text{tgt}$ (Contrastive attribution target function)
\Procedure{PECoRe}{$C, x, \theta, s_\text{cti}, s_\text{cci}, \mathcal{M}, f_\text{att}, f_\text{tgt}$}
  \State $\hat y = \textnormal{generate(}C, x, \theta$) using any decoding strategy and parameters
  \State $\mathcal{T} = \textnormal{CTI(}C, x, \hat y, \theta, \mathcal{M}, s_\text{cti}\textnormal{)}$
  \ForAll{$t \in \mathcal{T}$}
    \State $\mathcal{C}_t = \textnormal{CCI(}t, C, x, \hat y, \theta, f_\text{att}, f_\text{tgt}, s_\text{cci}\textnormal{)}$
    \ForAll{$c \in \mathcal{C}_t$}
      \State Store $(C_c, \hat y_t)$ in $S_\text{ct}$
    \EndFor
  \EndFor
  \State \textbf{return} $S_\text{ct}$ // Set of cue-target pairs
\EndProcedure
\Procedure{CTI}{$C, x, \hat y, \theta, \mathcal{M}, s_\text{cti}$}
    \State $\mathcal{T} = \emptyset$ // Empty set for context-sensitive indices of $\hat y$ tokens
    \ForAll{$\hat{y}_i \in \hat{y}$}
        \ForAll{$m \in \mathcal{M}$}
            \State $m^i = m_j \big(P_{\text{ctx}}(\hat{y}_i), P_{\text{no-ctx}}(\hat{y}_i) \big)$
        \EndFor
        \If{$(s_{\text{cti}}(m_1^i, \dots, m_M^i) = 1$)}
            \State Store $i$ in set $\mathcal{T}$
        \EndIf
    \EndFor
    \State \textbf{return} $\mathcal{T}$
\EndProcedure
\Procedure{CCI}{$t, C, x, \hat y, \theta, f_\text{att}, f_\text{tgt}, s_\text{cci}$}
    \State $\mathcal{C}_t = \emptyset$ // Empty set for contextual cues for target token $t$
    \State Generate constrained non-contextual target current sequence $\tilde y^*$ from $\hat y_{<t}$
    \State Use attribution method $f_\text{att}$ with attribution target $f_\text{tgt}$ to get input importance scores $A_t$
    \State Identify the subset $A_{t\,\text{ctx}}$ corresponding to tokens of context $C = \{ C_1, \dots, C_K\}$
    \ForAll{$a_i \in A_{t\,\text{ctx}} = \{a_1, \dots, a_K\}$}
        \If{$s_\text{cci}(a_i) = 1$}
            \State Store $C_i$ in $\mathcal{C}_t$
        \EndIf
    \EndFor
    \State \textbf{return} $\mathcal{C}_t$ 
\EndProcedure
\end{algorithmic}
\end{algorithm}
```

### Details on Translation Evaluation {#sec-pecore-appendix-eval-details}

We compute BLEU using the SACREBLEU library [@post-2018-call] with default parameters `nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1`.
The models fine-tuned with source and target context clearly outperform the ones trained with source only, both in terms of generic translation quality and context-sensitive disambiguation accuracy.
This motivates our choice to focus primarily on those models for our main analysis. All models are available in the following Huggingface organization: [`https://hf.co/context-mt`](https://hf.co/context-mt). The $S_{\text{ctx}}$ models correspond to those matching `context-mt/scat-<MODEL\_TYPE>-ctx4-cwd1-en-fr`, while $S+T_{\text{ctx}}$ models have the `context-mt/scat-<MODEL\_TYPE>-target-ctx4-cwd0-en-fr` identifier.

### Full CTI and CCI Results {#sec-pecore-appendix-cti-cci-results}

@fig-cti-f1-app and @fig-cti-auprc-app present the CTI plausibility of all tested models for the Macro F1 and AUPRC metrics, similarly to @fig-marian-big-f1-cti in the main analysis.

:::{#fig-cti-f1-app}

![](../figures/chap-4-pecore/macro_f1_cti_marian-small-scat_box.pdf){width=85% fig-align="center"}

![](../figures/chap-4-pecore/macro_f1_cti_marian-big-scat_box.pdf){width=85% fig-align="center"}

![](../figures/chap-4-pecore/macro_f1_cti_mbart50-1toM-scat_box.pdf){width=85% fig-align="center"}

![](../figures/chap-4-pecore/macro_f1_cti_marian-small-scat-target_box.pdf){width=85% fig-align="center"}

![](../figures/chap-4-pecore/macro_f1_cti_marian-big-scat-target_box.pdf){width=85% fig-align="center"}

![](../figures/chap-4-pecore/macro_f1_cti_mbart50-1toM-scat-target_box.pdf){width=85% fig-align="center"}

Macro F1 of contrastive metrics for context-sensitive target token identification (CTI) on the full datasets (left) or on [ok-cs]{.smallcaps} context-sensitive subsets (right). **Top to bottom:** ⓵ OpusMT Small S$_\text{ctx}$ ⓶ OpusMT Large S$_\text{ctx}$ ⓷ mBART-50 S$_\text{ctx}$ ⓸ OpusMT Small S+T$_\text{ctx}$ ⓹ OpusMT Large S+T$_\text{ctx}$ ⓺ mBART-50 S+T$_\text{ctx}$.
:::

:::{#fig-cti-auprc-app}
![](../figures/chap-4-pecore/auprc_cti_marian-small-scat_box.pdf){width=85% fig-align="center"}

![](../figures/chap-4-pecore/auprc_cti_marian-big-scat_box.pdf){width=85% fig-align="center"}

![](../figures/chap-4-pecore/auprc_cti_mbart50-1toM-scat_box.pdf){width=85% fig-align="center"}

![](../figures/chap-4-pecore/auprc_cti_marian-small-scat-target_box.pdf){width=85% fig-align="center"}

![](../figures/chap-4-pecore/auprc_cti_marian-big-scat-target_box.pdf){width=85% fig-align="center"}

![](../figures/chap-4-pecore/auprc_cti_mbart50-1toM-scat-target_box.pdf){width=85% fig-align="center"}

Area Under Precision-Recall Curve (AUPRC) of contrastive metrics for context-sensitive target token identification (CTI) on the full datasets (left) or on [ok-cs]{.smallcaps} context-sensitive subsets (right). **Top to bottom:** ⓵ OpusMT Small S$_\text{ctx}$ ⓶ OpusMT Large S$_\text{ctx}$ ⓷ mBART-50 S$_\text{ctx}$ ⓸ OpusMT Small S+T$_\text{ctx}$ ⓹ OpusMT Large S+T$_\text{ctx}$ ⓺ mBART-50 S+T$_\text{ctx}$.
:::

@fig-cci-f1-app @fig-cci-auprc-app present the CCI plausibility of all tested models for the Macro F1 and AUPRC metrics, similarly to @fig-marian-big-f1-cci in the main analysis.

:::{#fig-cci-f1-app}

![](../figures/chap-4-pecore/macro_f1_cci_marian-small-scat+tgt_box.pdf){width=100% fig-align="center"}

![](../figures/chap-4-pecore/macro_f1_cci_marian-big-scat+tgt_box.pdf){width=100% fig-align="center"}

![](../figures/chap-4-pecore/macro_f1_cci_mbart50-1toM-scat+tgt_box.pdf){width=100% fig-align="center"}

Macro F1 of CCI methods over full datasets using models trained with only source context (left) or with source+target context (right). Boxes and red median lines show CCI results based on gold context-sensitive tokens. Dotted bars show  median CCI scores obtained from context-sensitive tokens identified by KL-Divergence during CTI (E2E settings). **Top to bottom:** ⓵ OpusMT Small S$_\text{ctx}$ and S+T$_\text{ctx}$ ⓶ OpusMT Large S$_\text{ctx}$ and S+T$_\text{ctx}$ ⓷ mBART-50 S$_\text{ctx}$ and S+T$_\text{ctx}$.
:::

:::{#fig-cci-auprc-app}
![](../figures/chap-4-pecore/auprc_cci_marian-small-scat+tgt_box.pdf){width=100% fig-align="center"}

![](../figures/chap-4-pecore/auprc_cci_marian-big-scat+tgt_box.pdf){width=100% fig-align="center"}

![](../figures/chap-4-pecore/auprc_cci_mbart50-1toM-scat+tgt_box.pdf){width=100% fig-align="center"}

Area Under Precision-Recall Curve (AUPRC) of CCI methods over full datasets using models trained with only source context (left) or with source+target context (right). Boxes and red median lines show CCI results based on gold context-sensitive tokens. Dotted bars show  median CCI scores obtained from context-sensitive tokens identified by KL-Divergence during CTI (E2E settings). **Top to bottom:** ⓵ OpusMT Small S$_\text{ctx}$ and S+T$_\text{ctx}$ ⓶ OpusMT Large S$_\text{ctx}$ and S+T$_\text{ctx}$ ⓷ mBART-50 S$_\text{ctx}$ and S+T$_\text{ctx}$.
:::