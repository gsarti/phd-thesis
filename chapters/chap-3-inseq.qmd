---
nocite: |
    @simonyan-etal-2014-saliency
---

# Attributing Language Model Generations with the Inseq Toolkit {#chap-3-inseq}

> This chapter is adapted from the paper *Inseq: An Interpretability Toolkit for Sequence Generation Models* [@sarti-etal-2023-inseq].

Recent years saw an increase in studies and tools aimed at improving our behavioral or mechanistic understanding of neural language models [@belinkov-glass-2019-analysis].

Many studies applied such techniques to modern deep learning architectures, including Transformers [@vaswani-etal-2017-attention], leveraging gradients [@baherens-etal-2010-explain; @sundararajan-etal-2017-ig], attention patterns [@xu-etal-2015-show; @clark-etal-2019-bert] and input perturbations [@zeiler-fergus-2014-visualizing; @feng-etal-2018-pathologies] to quantify input importance, often leading to controversial outcomes in terms of faithfulness, plausibility and overall usefulness of such explanations [@adebayo-etal-2018-sanity; @jain-wallace-2019-attention; @jacovi-goldberg-2020-towards; @zafar-etal-2021-lack].

However, feature attribution techniques have mainly been applied to classification settings [@atanasova-etal-2020-diagnostic; @wallace-etal-2020-interpreting; @madsen-etal-2022-evaluating; @chrysostomou-aletras-2022-empirical], with relatively little interest in the more convoluted mechanisms underlying generation. Classification attribution is a single-step process resulting in one importance score per input token, often allowing for intuitive interpretations in relation to the predicted class. Sequential attribution^[We use *sequence generation* to refer to all iterative tasks including (but not limited to) natural language generation.] instead involves a computationally expensive multi-step iteration producing a matrix $A_{ij}$ representing the importance of every input $i$ in the prediction of every generation outcome $j$ ([@fig-inseq-teaser]).

Moreover, since previous generation steps causally influence following predictions, they must be dynamically incorporated into the set of attributed inputs throughout the process.
Lastly, while classification usually involves a limited set of classes and simple output selection (e.g. argmax after softmax), generation routinely works with large vocabularies and non-trivial decoding strategies [@eikema-aziz-2020-map]. These differences limited the use of feature attribution methods for generation settings, with relatively few works improving attribution efficiency [@vafa-etal-2021-rationales; @ferrando-etal-2022-towards] and explanations' informativeness [@yin-neubig-2022-interpreting].

![Feature importance and next-step probability extraction and visualization using Inseq with a ü§ó Transformers causal language model.](../figures/chap-3-inseq/teaser.pdf){#fig-inseq-teaser width=65%}

In this section, we introduce **Inseq**, a Python library to democratize access to interpretability analyses of generative language models.
Inseq centralizes access to a broad set of feature attribution methods, sourced in part from the Captum [@kokhlikyan-etal-2020-captum] framework, enabling a fair comparison of different techniques for all sequence-to-sequence and decoder-only models in the popular ü§ó Transformers library [@wolf-etal-2020-transformers].
Thanks to its intuitive interface, users can easily integrate interpretability analyses into sequence generation experiments with just 3 lines of code ([@fig-code-short]).
Nevertheless, Inseq is also highly flexible, including cutting-edge attribution methods with built-in post-processing features 
<!-- (see [@sec:feat-attr]), supporting customizable attribution targets and enabling constrained decoding of arbitrary sequences (see [@sec:customize]). -->

::: {#fig-code-short layout="[0.5,-0.05,0.45]" layout-valign="center"}
```python
import inseq

# Load model and attrib. method
model = inseq.load_model(
    "google/flan-t5-base",
    "integrated_gradients"
)
# Answer and attribute generation
attr_out = model.attribute(
    "Does 3 + 3 equal 6?",
    attribute_target=True
)
# Visualize the attribution,
# apply token-level aggregation
attr_out.show()
```

![](../figures/chap-3-inseq/flant5_math_attribution_example.png){width=50% fig-align="center"}

Computing and visualizing source and target-side attributions using Flan-T5 [@chung-etal-2022-scaling].
:::

In terms of usability, Inseq greatly simplifies access to local and global explanations with built-in support for a command line interface (CLI), optimized batching enabling dataset-wide attribution, and various methods to visualize, serialize and reload attribution outcomes and generated sequences ([@sec-chap2-usability]). Ultimately, Inseq aims to make sequence models first-class citizens in interpretability research and drive future advances in interpretability for generative applications.

## Related Work

[Feature Attribution for Sequence Generation]{.paragraph} Work on feature attribution for sequence generation has mainly focused on machine translation (MT). @bahdanau-etal-2015-neural showed how attention weights of neural MT models encode interpretable alignment patterns. @alvarez-melis-jaakkola-2017-causal adopted a perturbation-based framework to highlight biases in MT systems. @ding-etal-2019-saliency; @he-etal-2019-towards; @voita-etal-2021-analyzing; @voita-etal-2021-language *inter alia* conducted analyses on MT word alignments, coreference resolution and training dynamics with various gradient-based attribution methods. @vafa-etal-2021-rationales; @ferrando-etal-2022-towards developed approaches to efficiently compute sequential feature attributions without sacrificing accuracy. @yin-neubig-2022-interpreting introduced contrastive feature attribution to disentangle factors influencing generation in language models. Attribution scores obtained from MT models were also used to detect hallucinatory behavior [@dale-etal-2023-detecting; @tang-etal-2022-reducing; @xu-etal-2023-understanding], providing a compelling practical use case for such explanations.

[Tools for NLP Interpretability]{.paragraph} Although many post-hoc interpretability libraries were released recently, only a few support sequential feature attribution. Notably, LIT [@tenney-etal-2020-language], a structured framework for analyzing models across modalities, and Ecco [@alammar-2021-ecco], a library specialized in interactive visualizations of model internals. LIT is an all-in-one GUI-based tool to analyze model behaviors on entire datasets. However, the library does not provide out-of-the-box support for ü§ó Transformers models, requiring the definition of custom wrappers to ensure compatibility. Moreover, it has a steep learning curve due to its advanced UI, which might be inconvenient when working on a small amount of examples. All these factors limit LIT usability for researchers working with custom models, needing access to extracted scores, or being less familiar with interpretability research. On the other hand, Ecco is closer to our work, being based on ü§ó Transformers and having started to support encoder-decoder models concurrently with Inseq development. Despite a marginal overlap in their functionalities, the two libraries provide orthogonal benefits: Inseq's flexible interface makes it especially suitable for methodical quantitative analyses involving repeated evaluations, while Ecco excels in qualitative analyses aimed at visualizing model internals. Other popular tools such as ERASER [@deyoung-etal-2020-eraser], Thermostat [@feldhus-etal-2021-thermostat], transformers-interpret [@pierse-2021-transformers] and ferret [@attanasio-etal-2023-ferret] do not support sequence models.

## Design

Inseq combines sequence models sourced from ü§ó Transformers [@wolf-etal-2020-transformers] and attribution methods mainly sourced from Captum [@kokhlikyan-etal-2020-captum]. While only text-based tasks are currently supported, the library's modular design would enable the inclusion of other modeling frameworks, e.g. `fairseq` [@ott-etal-2019-fairseq], and modalities (e.g. speech) without requiring substantial redesign. Optional dependencies include ü§ó Datasets [@lhoest-etal-2021-datasets] and Rich.^[[`https://github.com/Textualize/rich`](https://github.com/Textualize/rich)] [@fig-inseq-class-structure] presents the Inseq hierarchy of models and attribution methods. The model-method connection enables out-of-the-box attribution using the selected method. Framework-specific and architecture-specific classes enable extending Inseq to new modeling architectures and frameworks.

![Inseq models and attribution methods. [Concrete]{color="brand-color.white" bg-color="brand-color.lightreddim"} [classes]{color="brand-color.white" bg-color="brand-color.lightbluedim"} combine abstract [framework]{color="brand-color.white" bg-color="brand-color.lightredclear"} and [architecture]{color="brand-color.white" bg-color="brand-color.lightredclear"} attribution models classes, and are derived from abstract attribution methods' [categories]{color="brand-color.white" bg-color="brand-color.lightblueclear"}.](../figures/chap-3-inseq/class_structure.pdf){#fig-inseq-class-structure width=100%}

### Guiding Principles

- **Research and Generation-oriented:** Inseq should support interpretability analyses of a broad set of sequence generation models without focusing narrowly on specific architectures or tasks. Moreover, the inclusion of new, cutting-edge methods should be prioritized to enable fair comparisons with well-established ones.

- **Scalable:** The library should provide an optimized interface to a wide range of use cases, models and setups, ranging from interactive attributions of individual examples using toy models to compiling statistics of large language models' predictions for entire datasets.

- **Beginner-friendly:** Inseq should provide built-in access to popular frameworks for sequence generation modeling and be fully usable by non-experts at a high level of abstraction, providing sensible defaults for supported attribution methods.

- **Extensible:** Inseq should support a high degree of customization for experienced users, with out-of-the-box support for user-defined solutions to enable future investigations into models' behaviors.

### Feature Attribution and Post-processing {#sec-chap2-feat-attr}

{{< include ../tables/chap-3-inseq/_methods.qmd >}}

At its core, Inseq provides a simple interface to apply feature attribution techniques for sequence generation tasks. We categorize methods in three groups, *gradient-based*, *internals-based* and *perturbation-based*, depending on their underlying approach to importance quantification.^[We distinguish between gradient- and internals-based methods to account for their difference in scores' granularity.] [@tbl-methods] presents the full list of supported methods. Aside from popular model-agnostic methods, Inseq notably provides built-in support for attention weight attribution and the cutting-edge Discretized Integrated Gradients method [@sanyal-ren-2021-discretized]. Moreover, multiple methods allow for the importance attribution of custom intermediate model layers, simplifying studies on representational structures and information mixing in sequential models, such as our case study of [@sec-chap2-rome-repro].

[Source and target-side attribution]{.paragraph} When using encoder-decoder architectures, users can set the `attribute_target` parameter to include or exclude the generated prefix in the attributed inputs. In most cases, this should be desirable to account for recently generated tokens when explaining model behaviors, such as when to terminate the generation (e.g. relying on the presence of `_yes` in the target prefix to predict `</s>` in [@fig-code-short], right matrix). However, attributing the source side separately could prove useful, for example, to derive word alignments from importance scores.

[Post-processing of attribution outputs]{.paragraph} Aggregation is a fundamental but often overlooked step in attribution-based analyses since most methods produce neuron-level or subword-level importance scores that would otherwise be difficult to interpret. Inseq includes several `Aggregator` classes to perform attribution aggregation across various dimensions. For example, the input word `Explanation` could be tokenized in two subword tokens `Expl` and `anation`, and each token would receive $N$ importance scores, with $N$ being the model embedding dimension. In this case, aggregators could first merge subword-level scores into word-level scores, and then merge granular embedding-level scores to obtain a single token-level score that is easier to interpret. Moreover, aggregation could prove especially helpful for long-form generation tasks such as summarization, where word-level importance scores could be aggregated to obtain a measure of sentence-level relevance. Notably, Inseq allows chaining multiple aggregators like in the example above using the `AggregatorPipeline` class, and provides a `PairAggregator` to aggregate different attribution maps, simplifying the conduction of contrastive analyses as in [@sec-chap2-gender-bias].^[See [@sec-inseq-appendix-pair-agg-gender-swap] for an example.]

### Customizing generation and attribution {#sec-chap2-customize}

During attribution, Inseq first generates target tokens using ü§ó Transformers and then attributes them step by step. If a custom target string is specified alongside model inputs, the generation step is instead skipped, and the provided text is attributed by constraining the decoding of its tokens.^[Constrained decoding users should be aware of its limitations in the presence of a high distributional discrepancy with natural model outputs [@vamvas-sennrich-2021-limits].] Constrained attribution can be used, among other things, for contrastive comparisons of minimal pairs and to obtain model justifications for desired outputs.

[Custom step functions]{.paragraph} At every attribution step, Inseq can use models' internal information to extract scores of interest (e.g. probabilities, entropy) that can be useful, among other things, to quantify model uncertainty (e.g. how likely the generated `_yes` token was given the context in [@fig-code-short]). Inseq provides access to multiple built-in step functions ([@tbl-methods], *S*) enabling the computation of these scores, and allows users to create and register new custom ones. Step scores are computed together with the attribution, returned as separate sequences in the output, and visualized alongside importance scores (e.g. the $p(y_t|y_{<t})$ row in [@fig-inseq-teaser]).

[Step functions as attribution targets]{.paragraph} For methods relying on model outputs to predict input importance (gradient and perturbation-based), feature attributions are commonly obtained from the model's output logits or class probabilities [@bastings-etal-2022-will]. However, recent work showed the effectiveness of using targets such as the probability difference of a contrastive output pair to answer interesting questions like "What inputs drive the prediction of $y$ rather than $\hat{y}$?" [@yin-neubig-2022-interpreting]. In light of these advances, Inseq users can leverage any built-in or custom-defined step function as an attribution target, enabling advanced use cases like contrastive comparisons and uncertainty-weighted attribution using MC Dropout [@gal-ghahramani-2016-dropout].

### Usability Features {#sec-chap2-usability}

- **Batched and span-focused attributions:** The library provides built-in batching capabilities, enabling users to go beyond single sentences and attribute even entire datasets in a single function call. When the attribution of a specific span of interest is needed, Inseq also allows specifying a start and end position for the attribution process. This functionality greatly accelerates the attribution process for studies on localized phenomena (e.g. pronoun coreference in MT models).

- **CLI, serialization and visualization:** The Inseq library offers an API to attribute single examples or entire ü§ó Datasets from the command line and save resulting outputs and visualizations to a file. Attribution outputs can be saved and loaded in JSON format with their respective metadata to easily identify the provenance of contents. Attributions can be visualized in the command line or IPython notebooks and exported as HTML files

- **Quantized model attribution:** Supporting the attribution of large models is critical given recent scaling tendencies [@kaplan-etal-2020-scaling]. All models allowing for quantization using `bitsandbytes` [@dettmers-etal-2022-gpt3] can be loaded in 8-bit directly from ü§ó Transformers, and their attributions can be computed normally using Inseq.^[`bitsandbytes 0.37.0` required for backward method, see [@sec-inseq-appendix-factual-knowledge] for an example.] A minimal manual evaluation of 8-bit attribution outputs for [@sec-chap2-rome-repro] study shows minimal discrepancies compared to full-precision results.

## Case Studies {#sec-chap2-case-studies}

### Gender Bias in Machine Translation {#sec-chap2-gender-bias}

In the first case study, we use Inseq to investigate gender bias in MT models. Studying social biases embedded in these models is crucial to understand and mitigate the representational and allocative harms they might engender [@blodgett-etal-2020-language].
@savoldi-etal-2021-gender note that the study of bias in MT could benefit from explainability techniques to identify spurious cues exploited by the model and the interaction of different features that can lead to intersectional bias.

[Synthetic Setup: Turkish to English]{#chap2-par-gender-bias .paragraph} The Turkish language uses the gender-neutral pronoun *o*, which can be translated into English as either `he`, `she`, or `it`, making it interesting to study gender bias in MT when associated with a language such as English for which models will tend to choose a gendered pronoun form. Previous works leveraged translations from gender-neutral languages to show gender bias present in translation systems [@cho-etal-2019-measuring,@prates-etal-2020-assessing,@farkas-nemeth-2022-measure].
We repeat this simple setup using a Turkish-to-English MarianMT model [@tiedemann-2020-tatoeba] and compute different metrics to quantify gender bias using Inseq.

We select 49 Turkish occupation terms verified by a native speaker (see [@sec-inseq-appendix-turkish-gender-bias]) and use them to infill the template sentence *O bir* ____ (He/She is a(n) ____). For each translation, we compute attribution scores for source Turkish pronoun ($x_\text{pron}$) and occupation ($x_\text{occ}$) tokens^[For multi-token occupation terms, e.g., *bilim insanƒ±* (scientist), the attribution score of the first token was used.] when generating the target English pronoun ($y_\text{pron}$) using Integrated Gradients (IG), Gradients ($\nabla$), and Input $\times$ Gradient (I$\times$G).^[We set approx. steps to ensure convergence $\Delta < 0.05$ for IG. All methods use the L2 norm to obtain token-level attributions.] We also collect target pronoun probabilities ($p(y_\text{pron})$), rank the 49 occupation terms using these metrics, and finally compute Kendall's $\tau$ correlation with the percentage of women working in the respective fields, using U.S. labor statistics as in previous works [e.g., @caliskan-etal-2017-semantics,@rudinger-etal-2018-gender]. [@tbl-turkish-gender-bias] presents our results.

{{< include ../tables/chap-3-inseq/_turkish-gender-bias.qmd >}}

In the **base case**, we correlate the different metrics with how much the gender distribution deviates from an equal distribution ($50-50\%$) for each occupation (i.e., the gender bias irrespective of the direction). We observe a strong gender bias, with `she` being chosen only for 5 out of 49 translations and gender-neutral variants never being produced by the MT model. We find a low correlation between pronoun probability and the degree of gender stereotype associated with the occupation. Moreover, we note a weaker correlation for IG compared to the other two methods. For those, attribution scores for $x_\text{occ}$ show significant correlations with labor statistics, supporting the intuition that the MT model will accord higher importance to source occupation terms associated to gender-stereotypical occupations when predicting the gendered target pronoun.

In the **gender-swap case** (‚ôÄÔ∏è $\rightarrow$ ‚ôÇÔ∏è), we use the `PairAggregator` class to contrastively compare attribution scores and probabilities when translating the pronoun as `She` or `He`.^[An example is provided in [@sec-inseq-appendix-pair-agg-gender-swap].]
We correlate resulting scores with the percentage of women working in the respective occupation and find strong correlations for $p(y_\text{pron})$, supporting the validity of contrastive approaches in uncovering gender bias.

[Qualitative Example: English to Dutch]{#chap2-par-gender-bias-bug .paragraph} We also qualitatively analyze biased MT outputs, showing how attributions can help develop hypotheses about models' behavior. [@tbl-m2m-gender-example] (top) shows the I $\times$ G attributions for English-to-Dutch translation using M2M-100 [@fan-etal-2021-m2m100].

{{< include ../tables/chap-3-inseq/_m2m-gender-example.qmd >}}

The model mistranslates the pronoun `her` into the masculine form *zijn* (his). We find that the wrongly translated pronoun exhibits high probability but does not associate substantial importance to the source occupation term *teacher*. Instead, we find good relative importance for the preceding word and *leraar* (male teacher). This suggests a strong prior bias for masculine variants, shown by the pronoun *zijn* and the noun *leraar*, as a possible cause for this mistranslation. When considering the contrastive example obtained by swapping *leraar* with its gender-neutral variant *leerkracht* ([@tbl-m2m-gender-example], bottom), we find increased importance of the target occupation in determining the correctly-gendered target pronoun *haar* (her). Our results highlight the tendency of MT models to attend inputs sequentially rather than relying on context, hinting at the known benefits of context-aware models for pronoun translation [@voita-etal-2018-context].

### Locating Factual Knowledge inside GPT-2 with Contrastive Attribution Tracing {#sec-chap2-rome-repro}

For our second case study, we experiment with a novel attribution-based technique to locate factual knowledge encoded in the layers of GPT-2 1.5B [@radford-etal-2019-language]. Specifically, we aim to reproduce the results of @meng-etal-2022-rome, showing the influence of intermediate layers in mediating the recall of factual statements such as `The Eiffel Tower is located in the city of` $\rightarrow$ `Paris`. @meng-etal-2022-rome estimate the effect of network components in the prediction of factual statements as the difference in probability of a correct target (e.g. *Paris*), given a corrupted subject embedding (e.g. for *Eiffel Tower*), before and after restoring clean activations for some input tokens at different layers of the network. Apart from the obvious importance of final token states in terminal layers, their results highlight the presence of an early site associated with the last subject token playing an important role in recalling the network's factual knowledge ([@fig-rome-repro], top).

![**Top:** Estimated causal importance of GPT-2 XL layers for predicting factual associations, as reported by @meng-etal-2022-rome. **Bottom:** Average GPT-2 XL Gradient $\times$ Layer Activation scores obtained with Inseq using contrastive factual pairs as attribution targets.](../figures/chap-3-inseq/rome-repro.pdf){#fig-rome-repro width=65%}

To verify such results, we propose a novel knowledge location method, which we name **Contrastive Attribution Tracing** (CAT), adopting the contrastive attribution paradigm of @yin-neubig-2022-interpreting to locate relevant network components by attributing minimal pairs of correct and wrong factual targets (e.g. *Paris* vs. *Rome* for the example above). To perform the contrastive attribution, we use the Layer Gradient $\times$ Activation method, a layer-specific variant of Input $\times$ Gradient, to propagate gradients up to intermediate network activations instead of reaching input tokens. The resulting attribution scores hence answer the question *"How important are layer $L$ activations for prefix token $t$ in predicting the correct factual target over a wrong one?"*. We compute attribution scores for 1000 statements taken from the Counterfact Statement dataset [@meng-etal-2022-rome] and present averaged results in [@fig-rome-repro] (bottom).^[[@fig-ex-cat-counterfact-plots] of [@sec-inseq-appendix-factual-knowledge] presents some examples.] Our results closely match those of the original authors, providing further evidence of how attribution methods can be used to identify salient network components and guide model editing, as shown by @dai-etal-2022-knowledge and @nanda-2023-attribution.

To our best knowledge, the proposed CAT method is the most efficient knowledge location technique to date, requiring only a single forward and backward pass of the attributed model. Patching-based approaches such as causal mediation [@meng-etal-2022-rome], on the other hand, provide causal guarantees of feature importance at the price of being more computationally intensive. Despite lacking the causal guarantees of such methods, CAT can provide an approximation of feature importance and greatly simplify the study of knowledge encoded in large language model representations thanks to its efficiency.

## Conclusion and Next Steps {#sec-conclusion}

We introduced Inseq, an easy-to-use but versatile toolkit for interpreting sequence generation models. With many libraries focused on the study of classification models, Inseq is the first tool explicitly aimed at analyzing systems for tasks such as machine translation, code synthesis, and dialogue generation. Researchers can easily add interpretability evaluations to their studies using our library to identify unwanted biases and interesting phenomena in their models' predictions. We plan to provide continued support and explore developments for Inseq, to provide simple and centralized access to a comprehensive set of thoroughly-tested implementations for the interpretability community. 

We plan to continuously expand the core functionality of the library by adding support for a wider range of attribution methods. Besides new methods, we also intend to significantly improve result visualization using an interactive interface backed by Gradio Blocks ^[[`https://gradio.app/docs/gradio/blocks`](https://www.gradio.app/docs/gradio/blocks)], work on interoperability features together with `ferret` developers [@attanasio-etal-2023-ferret] to simplify the evaluation of sequence attributions, and include sequential instance attribution methods for training data attribution [@lam-etal-2022-analyzing,@jain-etal-2022-influence].

In conclusion, we believe that Inseq has the potential to drive real progress in explainable language generation by accelerating the development of new analysis techniques, and we encourage members of this research field to join our development efforts.
